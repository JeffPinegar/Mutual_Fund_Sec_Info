{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to scrap https://finance.yahoo.com\n",
    "\n",
    "Tring to do this with reqests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack Overflow URL to scrape\n",
    "url = 'https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "html_content = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(html_content.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results and look for a ul with the class 'querylist'\n",
    "#result = soup.find('ul', class_='querylist')\n",
    "\n",
    "Industry_sector = soup.find_all('div', class_='Bdbw(1px) Bdbc($seperatorColor) Bdbs(s) H(25px) Pt(10px)')\n",
    "\n",
    "# Retrieve each list item\n",
    "#queries = result.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL to scrape\n",
    "url = 'https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX'\n",
    "\n",
    "# Make a request to the URL and get the HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the table containing the sector weightings\n",
    "table = soup.find('table', attrs={'data-test': 'Sector Weightings (%)'})\n",
    "\n",
    "# Find all the rows in the table\n",
    "rows = table.tbody.find_all('tr')\n",
    "\n",
    "# Create an empty dictionary to store the sector weightings\n",
    "sector_weightings = {}\n",
    "\n",
    "# Loop through each row in the table\n",
    "for row in rows:\n",
    "    # Get the sector name and weighting\n",
    "    sector_name = row.find_all('Ta')[0].text.strip()\n",
    "    sector_weighting = float(row.find_all('td')[1].text.strip('%')) / 100\n",
    "    \n",
    "    # Add the sector weighting to the dictionary\n",
    "    sector_weightings[sector_name] = sector_weighting\n",
    "\n",
    "# Print the sector weightings\n",
    "print(sector_weightings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span>Sector Weightings (%)</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<div class=\"Bdbw(1px) Bdbc($seperatorColor) Bdbs(s) H(20px) Pt(10px) C($tertiaryColor) Fz(xs) Fw(400)\">\n",
    "      <span class=\"W(40%) D(b) Fl(start) Ta(s)\">\n",
    "      <span>Sector(s)</span>\n",
    "      </span>\n",
    "      <span class=\"W(40%) D(b) Fl(start) Ta(e)\">\n",
    "      <div class=\"Bdw(1px) Bdc(t) Bds(s)\">\n",
    "      </div>\n",
    "      </span>\n",
    "      <span class=\"W(20%) D(b) Fl(start) Ta(e)\">\n",
    "      <span>VTSAX</span>\n",
    "      </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send an HTTP request to the URL of the webpage to be scraped\n",
    "url = 'https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the webpage using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the div that contains the sector weightings data\n",
    "sector_div = soup.find('div', {'class': 'M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)'}, string='Sector Weightings (%)')\n",
    "\n",
    "# Find the table that contains the sector weightings data\n",
    "table = sector_div.find_next_sibling('table')\n",
    "\n",
    "# Find all the rows in the table\n",
    "rows = table.tbody.find_all('tr')\n",
    "\n",
    "# Create an empty dictionary to store the sector weightings\n",
    "sector_weightings = {}\n",
    "\n",
    "# Loop through each row in the table\n",
    "for row in rows:\n",
    "    # Find the cells in the row\n",
    "    cells = row.find_all('td')\n",
    "    # Extract the sector name and weight percentage from the cells\n",
    "    sector = cells[0].text.strip()\n",
    "    weight = float(cells[1].text.strip().replace('%', ''))\n",
    "    # Add the sector and weight to the sector_weightings dictionary\n",
    "    sector_weightings[sector] = weight\n",
    "\n",
    "print(sector_weightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the div that contains the sector weightings\n",
    "sector_div = soup.find('h3', text='Sector Weightings (%)').parent\n",
    "\n",
    "# Find all the divs that contain sector names and weightings\n",
    "sector_data_divs = sector_div.find_all('div', class_='Fl(start)')\n",
    "\n",
    "# Create an empty dictionary to store the sector weightings\n",
    "sector_weightings = {}\n",
    "\n",
    "# Iterate over the sector data divs\n",
    "for div in sector_data_divs:\n",
    "    sector_name = div.find('span').text\n",
    "    sector_weight = float(div.find('span', class_='Trsdu(0.3s) ').text.strip('%'))\n",
    "    sector_weightings[sector_name] = sector_weight\n",
    "\n",
    "print(sector_weightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a request to the webpage\n",
    "response = requests.get('https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX')\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the div that contains the sector weightings\n",
    "sector_header = soup.find('h3', text='Sector Weightings (%)')\n",
    "if sector_header:\n",
    "    sector_div = sector_header.parent\n",
    "else:\n",
    "    print('Could not find Sector Weightings (%)')\n",
    "\n",
    "# Find all the divs that contain sector names and weightings\n",
    "if sector_div:\n",
    "    sector_data_divs = sector_div.find_all('div', class_='Fl(start)')\n",
    "else:\n",
    "    print('Sector div not found')\n",
    "    \n",
    "# Create an empty dictionary to store the sector weightings\n",
    "sector_weightings = {}\n",
    "\n",
    "# Extract the sector names and weightings from the divs\n",
    "if sector_data_divs:\n",
    "    for div in sector_data_divs:\n",
    "        sector_name = div.find('span').text\n",
    "        sector_weighting = float(div.find('span', attrs={'data-reactid': True}).text[:-1])\n",
    "        sector_weightings[sector_name] = sector_weighting\n",
    "else:\n",
    "    print('No sector data divs found')\n",
    "    \n",
    "print(sector_weightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Make a request\n",
    "url = 'https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the div that contains the sector weightings\n",
    "sector_div = soup.find('h3', text='Sector Weightings (%)').parent\n",
    "\n",
    "# Find all the divs that contain sector names and weightings\n",
    "sector_data_divs = sector_div.find_all('div', class_='Fl(start)')\n",
    "\n",
    "# Create an empty dictionary to store the sector weightings\n",
    "sector_weightings = {}\n",
    "\n",
    "# Iterate over the sector data divs\n",
    "for div in sector_data_divs:\n",
    "    # Get the sector name and weighting\n",
    "    sector_name = div.find('span', class_='Bdbw(1px) Bdbc($seperatorColor) Cur(p) Py(4px) Fw(500)').text\n",
    "    sector_weighting = div.find('span', class_='W(100%)').text\n",
    "    # Add the sector name and weighting to the dictionary\n",
    "    sector_weightings[sector_name] = sector_weighting\n",
    "\n",
    "print(sector_weightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website:  https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX\n",
    "\n",
    "# Import Splinter and BeautifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website:  https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX\n",
    "url = 'https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup object\n",
    "\n",
    "# This will open the url in the browser.  We must do it this way because the data we are looking for is not it the HTML if look at it outside of a browser.\n",
    "# The data is loaded with the webpage by a java script.  So if we just did a \"requests.get(url)\" the data we are after would not be there.  We must \n",
    "# load a browser and scrape/pars that.\n",
    "\n",
    "html = browser.html\n",
    "soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get news story titles\n",
    "\n",
    "Industry_sectors = []\n",
    "\n",
    "# Getting the titles\n",
    "# This is what I am looking for <div class=\"content_title\">\n",
    "Industry_sector = soup.find_all('div', class_='Bdbw(1px) Bdbc($seperatorColor) Bdbs(s) H(25px) Pt(10px)')\n",
    "\n",
    "for sector in Industry_sector:\n",
    "         print('-------------')\n",
    "         print(sector.text)\n",
    "         Industry_sectors.append(sector.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ishares.com/us/products/239726/ishares-core-sp-500-etf#'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "sector_table = soup.find('table', {'class': 'sustainability-details__table'})\n",
    "sector_rows = sector_table.find_all('tr')[1:]\n",
    "\n",
    "sector_dict = {}\n",
    "\n",
    "for row in sector_rows:\n",
    "    cells = row.find_all('td')\n",
    "    sector_name = cells[0].text.strip()\n",
    "    sector_weight = float(cells[1].text.strip().replace('%', '')) / 100\n",
    "    sector_dict[sector_name] = sector_weight\n",
    "\n",
    "print(sector_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website:  https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX\n",
    "\n",
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website:  https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX\n",
    "url = 'https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX'\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "#soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "sectors = {}\n",
    "\n",
    "for sector in soup.find_all('li', {'class': 'pf-nav-sectoral'}):\n",
    "    sector_name = sector.find('a').text.strip()\n",
    "    sector_weight = sector.find('span', {'class': 'pf-nav-percent'}).text.strip()\n",
    "    sectors[sector_name] = sector_weight\n",
    "    \n",
    "print(sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finance.yahoo.com/quote/VTSAX/holdings?p=VTSAX'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "sector_weightings = soup.find_all('div', {'class': 'Bdbw(1px) Bdbc($seperatorColor) Bdbs(s) H(25px) Pt(10px)'})\n",
    "\n",
    "sectors = {}\n",
    "for sector in sector_weightings:\n",
    "    sector_name = sector.find_all('span')[1].text\n",
    "    sector_weight = sector.find_all('span')[2].text\n",
    "    sectors[sector_name] = sector_weight\n",
    "    \n",
    "print(sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
